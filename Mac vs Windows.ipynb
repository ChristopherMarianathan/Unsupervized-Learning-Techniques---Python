{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "# MACBOOK VS WINDOWS ANALYSIS REPORT "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Introduction:**\n",
    "\n",
    "The age-old question of whether to buy a Mac or a Windows has not only been bothering us but the respective companies as well. A tremendous amount of effort goes into studying customer buying behavior by both companies. Our team has been commissioned by Apple to analyze behavior from the perspective of the Big Five personality as well as the Hult DNA traits (see Appendix A). The goal is to help Apple maintain customer retention and acquire customers who show a willingness to switch to Macbook. \n",
    "\n",
    "Our hypothesis is as follow: \n",
    "1. Macbook users have higher levels of extraversion, openness and thinking because they usually like retro designs, bold colors, and appreciate objects that express their individuality (Mac vs. PC People: Personality Traits & Aesthetic/Media Choices, 2009).\n",
    "2. Windows users have higher levels of conscientiousness and agreeableness and a lower level of thinking category; specifically men who are more down-to-earth, enjoy sports an number-oriented.\n",
    "\n",
    "**Insights and Recommendations Based on Psychology and Behaviors:**\n",
    " \n",
    "**Big Five based-strategy:**  \n",
    " \n",
    "*1. Customizable products and additional discounts for the Obsessive and Equanimous:* \n",
    "\n",
    "Both spontaneous and passionate customers who exhibit obsessive and equanimous traits prefer Macbook over Windows. These are people who are determined and can either act on sudden impulse or do not have any particular interest towards a specific product. However, both are willing to buy Windows rather than Macbook. This is because they both enjoy the ability to organize folders and have control over the computer itself; control is a behavior generally exhibited in people who have high obsessive - that can sometime be mistook as passionate - tendencies (Kelly, 2020). To increase their willingness to buy a Macbook, we must offer incentives to effectively persuade these individuals; evoke them to act on impulse or to give value. Therefore, giving incentives such as additional discounts on other Apple products or loyalty points or customizable features for a discounted price might increase their retention or even acquisition. Incentives can be provided via tailored email marketing or customer service via chat-box or phone calls. \n",
    " \n",
    "*2. Sales calls to the Indecisive:*\n",
    "\n",
    "Even though an Indecisive person owns a Macbook more than Windows, they are eager to switch to Windows or Chromebook. These customers are slow in the decision-making process and they don’t have a specific product in mind. Therefore, they go back and forth all the time. Through this behavior, it is easy to detect them because we can track their activity either on the website or mobile app via user acceptance of cookies and caches. To target these individuals, we can conduct A/B testing where they can easily connect with a sales representative. Providing tech support followed by email marketing - a summary of topics discussed - will alleviate the stress of having to decide. Meanwhile, on our end, we can track whether direct communication can lead to acquisition.\n",
    "\n",
    "**Hult DNA based-strategy:** \n",
    "\n",
    "*1) Boost brand presence through Social Media for Apathetic Trend Followers:*\n",
    "\n",
    "According to our data, Apathetic trend followers seem to prefer Macbooks for their next computer. These individuals tend to focus on themselves, not necessarily demonstrate a feeling or interest towards anything. However, they do prefer Macbook because of its simplicity, design, and impact led by the brand (Surur, 2019). Being of apathetic nature, they are also susceptible to things that are of hype. Moreover, our data suggest the samples collected were reflective of millennials. Research suggests that the millennials are the most impressionable, more subjective to trends, and can permanently change purchase behavior (Bona, 2021). During the pandemic, 60% of millennials claim that social media advertising influenced their purchase decision (Fry, 2020). With this knowledge, we can target apathetic millennials, specifically those on the younger end of the spectrum. This is because, based on our data, 65% of young millennials have shown interest in owning a Macbook. Therefore, we can develop strong online campaigns to demonstrate our brand values and vision, connect and nudge with apathetic millennials worldwide. \n",
    "\n",
    "*2) Conduct A/B Testing for Payment plan options to Apathetic Realists:*\n",
    "\n",
    "Apathetic Realists don’t seem to be interested in owning Macbooks as their next computer. Given the nature of their behavior, they are very cautious about their decisions. This suggests that price could be a significant factor in the lack of interest; as generally, a Macbook is more expensive than a Windows. Therefore, they lean on the conservative side and most likely don't like seeing large chunks of money leave their pockets. They often want to plan ahead and are rarely impulse shoppers (Caldwell, 2020). Therefore, we recommend doing A/B testing - providing them zero interest installments and see if this will add value to this customer group. In fact, many companies have begun adopting this method (Dickler, 2020), and especially in a pandemic or post-pandemic world, this group may become even more cautious with their money.\n",
    "\n",
    "3) It is important to note that when taking Hult DNA behaviors as a base, it is best to focus on acquiring customers rather than retaining them. As evident in our boxplots, there is distinctive insight between different personas with Hult DNA. \n",
    "\n",
    "**Additional Insights:**\n",
    "\n",
    "*1) Attract Customers with Affordable Trade-in options for South America:*\n",
    "\n",
    "The percentage of people who currently use Macbook is significantly higher in almost all regions, except for South America. However, when we analyze whether or not those users are willing to buy a Macbook in the future, the percentage of people who want to buy Macbooks by region is higher than the current user profile; meaning people who don’t use Macbook are willing to switch to Macbooks. This is due to Apple products costing higher in South America regions. For instance, in Brazil, a normal customer would need to work more than 6 months to afford a Macbook (Stangel, 2016). Therefore, with an emphasis on regions with the highest difference between current customers and willing-to-buy customers, we can create regional promotions such as affordable trade-ins. An affordable trade-in option will increase the eagerness of buying a Macbook for both current Mac users and aspiring Mac buyers.\n",
    " \n",
    "*2) Promotion through sports for male customers:* \n",
    "\n",
    "Currently, 42% of males own a Macbook, compared to the number of females at 61%. However, looking at how males who are willing to buy Macbook increases by 9%, there is an evident decline in male's Windows laptop preference. In comparison, females' preference for Macbooks stays almost similar. Therefore, it is better to focus on targeting males for future campaigns as that may result in higher retention and customer acquisition. Campaigns can be done through at sports events or commercials on the weekends where men have more time for leisure activities (Leadem, 2017).\n",
    "\n",
    "**Conclusion:**\n",
    "\n",
    "In conclusion, we have seen that traits have a huge impact on buying behaviors. We can confirm our first hypothesis as personalization is important for users who exhibit the Big 5 features to promote their individuality. Meanwhile, denouncing the second hypothesis, as Macbook users are also down-to-earth, thus, will be susceptible to promotional plans such as payment installments. Lastly, although it is important to develop a marketing strategy specifically for a certain persona, purchasing behaviors can also depend on other areas such as age, region and gender - as evident in additional insights found. \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CODE FOR INTERNAL ANALYTICS TEAM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load & Initial Exploration of Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "deletable": false,
    "editable": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "######################################\n",
    "# IMPORT DATA & LIBRARIES \n",
    "######################################\n",
    "\n",
    "# import libraries\n",
    "import numpy             as np                          # mathematical essentials\n",
    "import pandas            as pd                          # data science essentials\n",
    "import matplotlib.pyplot as plt                         # fundamental data visualization\n",
    "import seaborn           as sns                         # enhanced visualization\n",
    "from sklearn.preprocessing import StandardScaler        # standard scaler\n",
    "from sklearn.decomposition import PCA                   # pca\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage # dendrograms\n",
    "from sklearn.cluster         import KMeans              # k-means clustering\n",
    "\n",
    "# setting print options\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "\n",
    "# read featured engineered the file into Python\n",
    "computer = pd.read_excel(io ='survey_data.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "deletable": false,
    "editable": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# check data info\n",
    "# print(computer.info())\n",
    "\n",
    "\n",
    "# check missing values \n",
    "# print(computer.isnull().sum().any())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Insights:**\n",
    "- no missing values \n",
    "- 3 columns had duplicated questions; evident by the '.1' \n",
    "- some columns may need cleaning \n",
    "- need to drop object types and 'surveyID' to conduct PCA models "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean Dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1) REMOVE DUPLICATED COLUMNS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Step 1: combine duplicates and take the average \n",
    "\n",
    "# col: Respond effectively to multiple priorities\n",
    "computer.iloc[:,55] = (computer.iloc[:,58] + computer.iloc[:,55])/2\n",
    "\n",
    "# col: Take initiative even when circumstances, objectives, or rules aren't clear\n",
    "computer.iloc[:,56] = (computer.iloc[:,59] + computer.iloc[:,56])/2\n",
    "\n",
    "# col: Encourage direct and open discussions\n",
    "computer.iloc[:,57] = (computer.iloc[:,60] + computer.iloc[:,57])/2\n",
    "\n",
    "\n",
    "# Step 2: drop the duplicated columns  \n",
    "computer = computer.drop(computer.columns[[58, 59, 60]], axis = 1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2) REORGANIZE 'NATIONALITY' COLUMN** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "deletable": false,
    "editable": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# define inputs that need to be cleaned \n",
    "nationality = {\"Indian\"      : \"India\",\n",
    "               \"indian\"      : \"India\",\n",
    "               \"indian.\"     : \"India\",\n",
    "               \"INDIAN\"      : \"India\",\n",
    "               \"Chinese\"     : \"China\",\n",
    "               \"chinese\"     : \"China\",\n",
    "               \"CHINA\"       : \"China\",\n",
    "               \"china\"       : \"China\",\n",
    "               \"German\"      : \"Germany\",\n",
    "               \"Mexican\"     : \"Mexico\",\n",
    "               \"mexican\"     : \"Mexico\",\n",
    "               \"Peruvian\"    : \"Peru\",\n",
    "               \"American\"    : \"USA\",\n",
    "               \"Russian\"     : \"Russia\",   \n",
    "               \"Norwegian\"   : \"Norway\",  \n",
    "               \"Colombian\"   : \"Colombia\",\n",
    "               \"colombian\"   : \"Colombia\",\n",
    "               \"Taiwan\"      : \"Taiwan\", \n",
    "               \"Brazilian\"   : \"Brazil\", \n",
    "               \"Vietnamese\"  : \"Vietnam\",\n",
    "               \"Thai\"        : \"Thailand\",\n",
    "               \"Nigerian\"    : \"Nigeria\",\n",
    "               \"nigerian\"    : \"Nigeria\",\n",
    "               \"Turkish\"     : \"Turkey\",    \n",
    "               \"Republic of Korea\" : \"South Korea\",\n",
    "               \"Korea\"       : \"South Korea\",\n",
    "               \"Indonesian\"  : \"Indonesia\",\n",
    "               \"Italian\"     : \"Italy\",\n",
    "               \"italian\"     : \"Italy\",\n",
    "               \"Ghanaian\"    : \"Ghana\",                 \n",
    "               \"British\"     : \"UK\",             \n",
    "               \"ecuador\"     : \"Ecuador\",\n",
    "               \"Ecuadorian\"  : \"Ecuador\",\n",
    "               \"Dominican\"    : \"Dominican Republic\", \n",
    "               \"Dominican \"   : \"Dominican Republic\", \n",
    "               \"Filipino\"    : \"Philippines\",  \n",
    "               \"Filipino \"    : \"Philippines\",  \n",
    "               \"Congolese\"   : \"Congo\",\n",
    "               \"Congolese (DR CONGO)\" : \"Congo\",\n",
    "               \"canadian\"    : \"Canada\",\n",
    "               \"Swiss\"       : \"Switzerland\",\n",
    "               \"Czech\"       : \"Czech Republic\",\n",
    "               \"Spanish\"     : \"Spain\",\n",
    "               \"Belgian \"    : \"Belgium\", \n",
    "               \"Venezuelan\"  : \"Venezuela\",\n",
    "               \"Ukrainian\"   : \"Ukraine\",\n",
    "               \"Ukrainia\"    : \"Ukraine\",\n",
    "               \"Pakistani\"   : \"Pakistan\",\n",
    "               \"Kenyan\"      : \"Kenya\",\n",
    "               \"Ugandan\"     : \"Uganda\",\n",
    "               \"Costarrican\" : \"Costa Rica\",\n",
    "               \"Portuguese\"  : \"Portugal\",   \n",
    "               \"Italian and Spanish\" : \"Dual Nationality\",\n",
    "               \"German/American\" : \"Dual Nationality\",\n",
    "               \"British, Indian\" : \"Dual Nationality\",  \n",
    "               \"prefer not to answer\" : \"Prefer not to answer\"\n",
    "    \n",
    "}\n",
    "\n",
    "# replace the matching strings\n",
    "computer.iloc[:,74].replace(nationality, inplace = True)\n",
    "\n",
    "# checking to see all is good\n",
    "# computer.iloc[:,74].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# group nationalities by regions --> new col: 'Regions'\n",
    "\n",
    "# placeholder for new column\n",
    "regions = []\n",
    "\n",
    "# For loop for region\n",
    "for nationality in computer.iloc[ : , 74]:\n",
    "    \n",
    "    if nationality == 'India' or nationality == 'China' \\\n",
    "    or nationality == 'Russia' or nationality == 'South Korea' \\\n",
    "    or nationality == 'Taiwan' or nationality == 'Indonesia' \\\n",
    "    or nationality == 'Vietnam' or nationality == 'Thailand' \\\n",
    "    or nationality == 'Philippines' or nationality == 'Japan'\\\n",
    "    or nationality == 'Japanese' or nationality == 'Kyrgyz'\\\n",
    "    or nationality == 'Kyrgyz'or nationality == 'Pakistan'\\\n",
    "    or nationality == 'Turkey':\n",
    "        regions.append('Asia')\n",
    "        \n",
    "\n",
    "    elif nationality == 'Germany' or nationality == 'Italy'\\\n",
    "    or nationality == 'Norway' or nationality == 'Spain'\\\n",
    "    or nationality == 'Czech Republic' or nationality == 'Belarus'\\\n",
    "    or nationality == 'Belgium' or nationality == 'Switzerland'\\\n",
    "    or nationality == 'Ukraine'or nationality == 'UK' \\\n",
    "    or nationality == 'Portugal' :\n",
    "        regions.append('Europe')\n",
    "\n",
    "        \n",
    "    elif nationality == 'Africa'   or nationality == 'Nigeria'\\\n",
    "    or nationality == 'Ghana'  or nationality == 'Kenya'\\\n",
    "    or nationality == 'Uganda' or nationality == 'Congo'\\\n",
    "    or nationality == 'Mauritius':\n",
    "        regions.append('Africa')\n",
    "   \n",
    "\n",
    "    elif nationality == 'Mexico'  or nationality == 'USA'\\\n",
    "    or nationality == 'Dominican Republic' or nationality == 'Canada'\\\n",
    "    or nationality == 'Panama' or nationality == 'Costa Rica':\n",
    "        regions.append('North America')\n",
    "     \n",
    "\n",
    "    elif nationality == 'Peru'    or nationality == 'Colombia'\\\n",
    "    or nationality == 'Brazil'   or nationality == 'Ecuador'\\\n",
    "    or nationality == 'Venezuela':\n",
    "        regions.append('South America')\n",
    "        \n",
    "        \n",
    "    elif nationality == 'Dual Nationality':\n",
    "        regions.append('Global')\n",
    "        \n",
    "    else:\n",
    "        regions.append('Prefer not to answer')\n",
    "\n",
    "# Create new columns\n",
    "computer['Regions'] = regions\n",
    "\n",
    "# check results \n",
    "computer['Regions'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore Dataset in Details"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1) LAPTOPS: CURRENT OWNERSHIP & FUTURE ASPIRATIONS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# current laptop ownership \n",
    "computer['What laptop do you currently have?'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# want new laptop \n",
    "next_laptop = computer['What laptop would you buy in next assuming if all laptops cost the same?']\n",
    "\n",
    "counts = next_laptop.value_counts()\n",
    "\n",
    "percent100 = next_laptop.value_counts(normalize=True).mul(100).round(1).astype(str) + '%'\n",
    "\n",
    "pd.DataFrame({'counts': counts, 'percentage' : percent100})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Insights:** \n",
    "- The percentage for 'Chromebook' is very little, consider it as an outlier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2) LAPTOPS & AGE GROUPS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# age x windows laptop\n",
    "computer['What is your age?'].plot.hist(color = 'blue',alpha = 0.5)\n",
    "\n",
    "# display plot\n",
    "computer['What is your age?']\\\n",
    "[computer['What laptop do you currently have?']=='Windows laptop'].plot.hist(color = 'red',\n",
    "                                                                             alpha = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# age x macbook \n",
    "computer['What is your age?'].plot.hist(color = 'blue',alpha = 0.5)\n",
    "\n",
    "# display plot\n",
    "computer['What is your age?']\\\n",
    "[computer['What laptop do you currently have?']=='Macbook'].plot.hist(color = 'yellow',\n",
    "                                                                      alpha = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "# median age = 26\n",
    "computer['What is your age?'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# current laptop + age\n",
    "\n",
    "# categorize younger and older millenials  \n",
    "young_m = computer['What is your age?'][computer['What is your age?'] <= 26]\n",
    "old_m = computer['What is your age?'][computer['What is your age?'] >  26]\n",
    "\n",
    "# set threshold\n",
    "young = computer[(computer['What is your age?'] <= 26) \\\n",
    "    & (computer['What laptop do you currently have?']=='Macbook')]['surveyID'].count()/ \\\n",
    "    computer[(computer['What is your age?'] <= 26)]['surveyID'].count()\n",
    "\n",
    "old = computer[(computer['What is your age?'] > 26) \\\n",
    "    & (computer['What laptop do you currently have?']=='Macbook')]['surveyID'].count()/ \\\n",
    "    computer[(computer['What is your age?'] > 26)]['surveyID'].count()\n",
    "\n",
    "# display results\n",
    "print(f\"\"\"\n",
    "Macbook ownership\n",
    "------------------\n",
    "% of young millenials: {young.round(2)}\n",
    "% of old millenials:   {old.round(2)}\n",
    "\"\"\"\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# future laptop + age\n",
    "\n",
    "# categorize younger and older millenials  \n",
    "young_m = computer['What is your age?'][computer['What is your age?'] <= 26]\n",
    "old_m = computer['What is your age?'][computer['What is your age?'] >  26]\n",
    "\n",
    "# set threshold\n",
    "young = computer[(computer['What is your age?'] <= 26) \\\n",
    "    & (computer['What laptop would you buy in next assuming if all laptops cost the same?']=='Macbook')]['surveyID'].count()/ \\\n",
    "    computer[(computer['What is your age?'] <= 26)]['surveyID'].count()\n",
    "\n",
    "old = computer[(computer['What is your age?'] > 26) \\\n",
    "    & (computer['What laptop would you buy in next assuming if all laptops cost the same?']=='Macbook')]['surveyID'].count()/ \\\n",
    "    computer[(computer['What is your age?'] > 26)]['surveyID'].count()\n",
    "\n",
    "# display results\n",
    "print(f\"\"\"\n",
    "Macbook ownership\n",
    "------------------\n",
    "% of young millenials: {young.round(2)}\n",
    "% of old millenials:   {old.round(2)}\n",
    "\"\"\"\n",
    "     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Insights:**\n",
    "- Comparing the distribution: both Macbook and Windows laptop share similar distribution with Age \n",
    "- However, students under the median, age of 26, seem to use more Macbooks than Windows \n",
    "- This is further supported by the % calculated, where more young millenials are owning Macbooks than older millenials "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3) LAPTOPS & GENDER GROUPS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# current laptop by gender \n",
    "\n",
    "# females with Macbook \n",
    "female = computer[(computer['Gender']!=\"Male\") & \\\n",
    "    (computer['What laptop do you currently have?']== 'Macbook')]['surveyID'].count()/ \\\n",
    "    computer[computer['Gender']!=\"Male\"]['surveyID'].count()\n",
    "\n",
    "# males with Macbook\n",
    "male = computer[(computer['Gender']==\"Male\") & \\\n",
    "    (computer['What laptop do you currently have?']== 'Macbook')]['surveyID'].count()/ \\\n",
    "    computer[computer['Gender']==\"Male\"]['surveyID'].count()\n",
    "\n",
    "# display results\n",
    "print(f\"\"\"\n",
    "Macbook ownership\n",
    "------------------\n",
    "% of female: {female.round(2)}\n",
    "% of male:   {male.round(2)}\n",
    "\"\"\"\n",
    "     )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# desire for Macbook by gender \n",
    "\n",
    "# females with Macbook \n",
    "female = computer[(computer['Gender']!=\"Male\") & \\\n",
    "    (computer['What laptop would you buy in next assuming if all laptops cost the same?']== 'Macbook')]['surveyID'].count()/ \\\n",
    "    computer[computer['Gender']!=\"Male\"]['surveyID'].count()\n",
    "\n",
    "# males with Macbook \n",
    "male = computer[(computer['Gender']==\"Male\") & \\\n",
    "    (computer['What laptop would you buy in next assuming if all laptops cost the same?']== 'Macbook')]['surveyID'].count()/ \\\n",
    "    computer[computer['Gender']==\"Male\"]['surveyID'].count()\n",
    "\n",
    "\n",
    "# display results\n",
    "print(f\"\"\"\n",
    "Macbook ownership\n",
    "------------------\n",
    "% of female: {female.round(2)}\n",
    "% of male:   {male.round(2)}\n",
    "\"\"\"\n",
    "     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Insights:**\n",
    "- In both cases, current and futures, females prefer Macbook over Windows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4) LAPTOP & REGIONS:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# current laptop + regions \n",
    "\n",
    "# Asia with Macbook\n",
    "as_m = computer[(computer['Regions']== \"Asia\") & \\\n",
    "    (computer['What laptop do you currently have?']== 'Macbook')]['surveyID'].count()/\\\n",
    "    computer[computer['Regions']==\"Asia\"]['surveyID'].count()\n",
    "\n",
    "# Europe with Macbook\n",
    "e_m = computer[(computer['Regions']==\"Europe\") & \\\n",
    "    (computer['What laptop do you currently have?']== 'Macbook')]['surveyID'].count()/\\\n",
    "    computer[computer['Regions']==\"Europe\"]['surveyID'].count()\n",
    "\n",
    "# Africa with Macbook\n",
    "af_m = computer[(computer['Regions']==\"Africa\") & \\\n",
    "    (computer['What laptop do you currently have?']== 'Macbook')]['surveyID'].count()/\\\n",
    "    computer[computer['Regions']==\"Africa\"]['surveyID'].count()\n",
    "\n",
    "# North America with Macbook\n",
    "na_m = computer[(computer['Regions']==\"North America\") & \\\n",
    "    (computer['What laptop do you currently have?']== 'Macbookp')]['surveyID'].count()/\\\n",
    "    computer[computer['Regions']==\"North America\"]['surveyID'].count()\n",
    "\n",
    "# South America with Macbook\n",
    "sa_m = computer[(computer['Regions']==\"South America\") & \\\n",
    "    (computer['What laptop do you currently have?']== 'Macbook')]['surveyID'].count()/\\\n",
    "    computer[computer['Regions']==\"South America\"]['surveyID'].count()\n",
    "\n",
    "# display results\n",
    "print(f\"\"\"\n",
    "Percentage of People with Macbooks by Regions:\n",
    "-----------------------------------------------\n",
    "Asia with Macbook:           {as_m.round(2)}\n",
    "Europe with Macbook:         {e_m.round(2)}\n",
    "Africa with Macbook:         {af_m.round(2)}\n",
    "North America with Macbook:  {na_m.round(2)}\n",
    "South America with Macbook:  {sa_m.round(2)}\n",
    "\"\"\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# aspiring laptop + regions \n",
    "\n",
    "# Asia with Macbook\n",
    "as_m = computer[(computer['Regions']==\"Asia\") & \\\n",
    "    (computer['What laptop would you buy in next assuming if all laptops cost the same?']== 'Macbook')]['surveyID'].count()/\\\n",
    "    computer[computer['Regions']==\"Asia\"]['surveyID'].count()\n",
    "\n",
    "# Africa with Macbook\n",
    "e_m = computer[(computer['Regions']==\"Africa\") & \\\n",
    "    (computer['What laptop would you buy in next assuming if all laptops cost the same?']== 'Macbook')]['surveyID'].count()/\\\n",
    "    computer[computer['Regions']==\"Africa\"]['surveyID'].count()\n",
    "\n",
    "\n",
    "# Europe with Macbook\n",
    "af_m = computer[(computer['Regions']==\"Europe\") & \\\n",
    "    (computer['What laptop would you buy in next assuming if all laptops cost the same?']== 'Macbook')]['surveyID'].count()/\\\n",
    "    computer[computer['Regions']==\"Europe\"]['surveyID'].count()\n",
    "\n",
    "\n",
    "# North America with Macbook\n",
    "na_m = computer[(computer['Regions']==\"North America\") & \\\n",
    "    (computer['What laptop would you buy in next assuming if all laptops cost the same?']== 'Macbook')]['surveyID'].count()/\\\n",
    "    computer[computer['Regions']==\"North America\"]['surveyID'].count()\n",
    "\n",
    "\n",
    "# South America with Macbook \n",
    "sa_m = computer[(computer['Regions']==\"South America\") & \\\n",
    "    (computer['What laptop would you buy in next assuming if all laptops cost the same?']== 'Macbook')]['surveyID'].count()/\\\n",
    "    computer[computer['Regions']==\"South America\"]['surveyID'].count()\n",
    "\n",
    "\n",
    "print(f\"\"\"\n",
    "Percentage of People who want Macbooks by Regions:\n",
    "-----------------------------------------------\n",
    "Asia with Macbook:           {as_m.round(2)}\n",
    "Europe with Macbook:         {e_m.round(2)}\n",
    "Africa with Macbook:         {af_m.round(2)}\n",
    "North America with Macbook:  {na_m.round(2)}\n",
    "South America with Macbook:  {sa_m.round(2)}\n",
    "\"\"\")   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Data for Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# store dictionary of 'demographic features' --> to drop for PCA \n",
    "demographic_features = ['surveyID',\n",
    "                         'What laptop do you currently have?',\n",
    "                         'What laptop would you buy in next assuming if all laptops cost the same?',\n",
    "                         'What program are you in?',\n",
    "                         'What is your age?',\n",
    "                         'Gender',\n",
    "                         'What is your nationality? ',\n",
    "                         'What is your ethnicity?',\n",
    "                         'Regions']\n",
    "                                                                  \n",
    "\n",
    "# dropping demographic features/ object types \n",
    "traits = computer.drop(demographic_features, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BIG 5 TRAITS\n",
    "\n",
    "The survey collected contain questions taken from the 'Big Five Personality Test'. Big Five Traits are 5 broad domains which define a person's overall personality based on their individual differences (Cherry, 2020). To group questions according to the official test, a formula provided by Temple University was adopted. The formula took into consideration that some questions juxtapose others. The formula is as follow:\n",
    "\n",
    "\n",
    "*Note: number in brackets refers to the question number in the test sheet*\n",
    "\n",
    "   - Extraversion      = 20 + (1) - (6) + (11) - (16) + (21) - (26) + (31) - (36) + (41) - (46) = ___\n",
    "   \n",
    "\n",
    "   - Agreeableness     = 14 - (2)  + (7)  - (12)  + (17)  - (22)  + (27)  - (32)  + (37)  +  (42)  + (47)  = ___\n",
    "\n",
    "\n",
    "   - Conscientiousness = 14 + (3)  - (8)  + (13)  - (18)  + (23)  - (28)  + (33)  - (38)  + (43)  +  (48)  = ___\n",
    "\n",
    "\n",
    "   - Neuroticism       = 38 - (4)  + (9)  - (14)  + (19)  - (24)  - (29)  - (34)  - (39)  - (44) - (49) = ___\n",
    "\n",
    "\n",
    "   - Openness          = 8 + (5)  - (10)  + (15)  - (20)  + (25)  - (30)  + (35)  + (40)  +  (45)  + (50)  = ___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# group columns and label according to traits\n",
    "\n",
    "# EXTRAVERSION \n",
    "e = [0, 5, 10, 15, 20, 25, 30, 35, 40, 45]\n",
    "extraversion = traits.iloc[:,e]    \n",
    "\n",
    "# AGREEABLENESS \n",
    "a = [1, 6, 11, 16, 21, 26, 31, 36, 41, 46]\n",
    "agreeableness = traits.iloc[:,a]     \n",
    "     \n",
    "# CONSCIENTIOUSNESS \n",
    "c = [2, 7, 12, 17, 22, 27, 32, 37, 42, 47]\n",
    "conscientiousness = traits.iloc[:,c]\n",
    "          \n",
    "# NEUROTICISM \n",
    "n = [3, 8, 13, 18, 23, 28, 33, 38, 43, 48]\n",
    "neuroticism = traits.iloc[:,n] \n",
    "         \n",
    "# OPENNESS\n",
    "o = [4, 9, 14, 19, 24, 29, 34, 39, 44, 49]\n",
    "openness = traits.iloc[:,o]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# aggregate results using position in list \n",
    "\n",
    "# sum of all extraversion points \n",
    "sum_extraversion = 20 + extraversion.iloc[:0] - extraversion.iloc[:,1]\\\n",
    "+ extraversion.iloc[:,2] - extraversion.iloc[:, 3] + extraversion.iloc[:, 4]\\\n",
    "- extraversion.iloc[:, 5] + extraversion.iloc[:, 6] - extraversion.iloc[:, 7]\\\n",
    "+ extraversion.iloc[:, 8] - extraversion.iloc[:, 9]\n",
    "\n",
    "# sum of all agreeableness points \n",
    "sum_agreeableness = 14 - agreeableness.iloc[:,0] + agreeableness.iloc[:,1]\\\n",
    "- agreeableness.iloc[:,2] + agreeableness.iloc[:, 3] - agreeableness.iloc[:, 4]\\\n",
    "+ agreeableness.iloc[:, 5] - agreeableness.iloc[:, 6] + agreeableness.iloc[:, 7]\\\n",
    "+ agreeableness.iloc[:, 8] + agreeableness.iloc[:, 9]\n",
    "\n",
    "# sum of all conscientiousness points \n",
    "sum_conscientiousness = 14 + conscientiousness.iloc[:,0]\\\n",
    "- conscientiousness.iloc[:,1] + conscientiousness.iloc[:,2]\\\n",
    "- conscientiousness.iloc[:, 3] + conscientiousness.iloc[:, 4]\\\n",
    "- conscientiousness.iloc[:, 5] + conscientiousness.iloc[:, 6]\\\n",
    "- conscientiousness.iloc[:, 7] + conscientiousness.iloc[:, 8]\\\n",
    "+ conscientiousness.iloc[:, 9]\n",
    "\n",
    "# sum of all neuroticism points \n",
    "sum_neuroticism = 38 - neuroticism.iloc[:,0] + neuroticism.iloc[:,1]\\\n",
    "- neuroticism.iloc[:,2] + neuroticism.iloc[:, 3] - neuroticism.iloc[:, 4]\\\n",
    "- neuroticism.iloc[:, 5] - neuroticism.iloc[:, 6] - neuroticism.iloc[:, 7]\\\n",
    "- neuroticism.iloc[:, 8] - neuroticism.iloc[:, 9]\n",
    "\n",
    "# sum of all openness points \n",
    "sum_openness = 8 + openness.iloc[:,0] - openness.iloc[:,1]\\\n",
    "+ openness.iloc[:,2] - openness.iloc[:, 3] + openness.iloc[:, 4]\\\n",
    "- openness.iloc[:, 5] + openness.iloc[:, 6] + openness.iloc[:, 7]\\\n",
    "+ openness.iloc[:, 8] + openness.iloc[:, 9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# save into Big 5 into 1 dataframe \n",
    "big5 = pd.DataFrame(list(zip(sum_extraversion, sum_agreeableness, \n",
    "                             sum_conscientiousness, sum_neuroticism, \n",
    "                             sum_openness)),\n",
    "                    columns=['EXTRAVERSION','AGREEABLENESS', \n",
    "                             'CONSCIENTIOUSNESS', 'NEUROTICISM', 'OPENNESS'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HULT DNA\n",
    "\n",
    "Hult DNA is set of cognitive-behavioral skills exhibited in every student at Hult. The 'DNA' is comprised of: Thinking, Communicating and Team Building (Shaheem, 2019). To balance opposite trait questions, the Big 5 formula was adopted and adjusted to best fit the Hult DNA questions. Questions were grouped as follow:\n",
    "- Each group had 6 questions total (5 positive and 1 negative behavior) \n",
    "- Each group was calculated as follow: Group =  sum of all positive behaviors - 1 negative behavior = ___\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# group columns and label according to traits\n",
    "\n",
    "# THINKING \n",
    "think = [50, 52, 53, 54, 65, 51]\n",
    "thinking = traits.iloc[:,think]   \n",
    "\n",
    "# COMMUNICATING \n",
    "com = [55, 56, 57, 63, 66, 58]\n",
    "communicating = traits.iloc[:,com]     \n",
    "     \n",
    "# TEAM BUILDING \n",
    "team = [59, 60, 61, 64, 67, 62]\n",
    "team_building = traits.iloc[:,team]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# aggregate results using position in list \n",
    "\n",
    "# sum of all thinking points \n",
    "sum_thinking = thinking.iloc[:,0] + thinking.iloc[:,1] + thinking.iloc[:,2]\\\n",
    "+ thinking.iloc[:, 3] + thinking.iloc[:, 4] - thinking.iloc[:, 5]\n",
    "\n",
    "# sum of all communication points \n",
    "sum_communication = communicating.iloc[:,0] + communicating.iloc[:,1] + communicating.iloc[:,2]\\\n",
    "+ communicating.iloc[:, 3] + communicating.iloc[:, 4] - communicating.iloc[:, 5]\n",
    "\n",
    "# sum of all team points \n",
    "sum_teambuilding = team_building.iloc[:,0] + team_building.iloc[:,1]\\\n",
    "+ team_building.iloc[:,2] + team_building.iloc[:, 3] + team_building.iloc[:, 4]\\\n",
    "- team_building.iloc[:, 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# save into Hult DNA into 1 dataframe \n",
    "hult = pd.DataFrame(list(zip(sum_thinking, sum_communication, sum_teambuilding)),\n",
    "                    columns=['THINKING','COMMUNICATING', 'TEAM BUILDING '])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load User Define Functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "########################################\n",
    "# inertia\n",
    "########################################\n",
    "def interia_plot(data, max_clust = 50):\n",
    "    \"\"\"\n",
    "PARAMETERS\n",
    "----------\n",
    "data      : DataFrame, data from which to build clusters. Dataset should be scaled\n",
    "max_clust : int, maximum of range for how many clusters to check interia, default 50\n",
    "    \"\"\"\n",
    "\n",
    "    ks = range(1, max_clust)\n",
    "    inertias = []\n",
    "\n",
    "\n",
    "    for k in ks:\n",
    "        # INSTANTIATING a kmeans object\n",
    "        model = KMeans(n_clusters = k)\n",
    "\n",
    "\n",
    "        # FITTING to the data\n",
    "        model.fit(data)\n",
    "\n",
    "\n",
    "        # append each inertia to the list of inertias\n",
    "        inertias.append(model.inertia_)\n",
    "\n",
    "\n",
    "\n",
    "    # plotting ks vs inertias\n",
    "    fig, ax = plt.subplots(figsize = (12, 8))\n",
    "    plt.plot(ks, inertias, '-o')\n",
    "\n",
    "\n",
    "    # labeling and displaying the plot\n",
    "    plt.xlabel('number of clusters, k')\n",
    "    plt.ylabel('inertia')\n",
    "    plt.xticks(ks)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "########################################\n",
    "# scree_plot\n",
    "########################################\n",
    "def scree_plot(pca_object, export = False):\n",
    "    # building a scree plot\n",
    "\n",
    "    # setting plot size\n",
    "    fig, ax = plt.subplots(figsize=(10, 8))\n",
    "    features = range(pca_object.n_components_)\n",
    "\n",
    "\n",
    "    # developing a scree plot\n",
    "    plt.plot(features,\n",
    "             pca_object.explained_variance_ratio_,\n",
    "             linewidth = 2,\n",
    "             marker = 'o',\n",
    "             markersize = 10,\n",
    "             markeredgecolor = 'black',\n",
    "             markerfacecolor = 'grey')\n",
    "\n",
    "\n",
    "    # setting more plot options\n",
    "    plt.title('Scree Plot')\n",
    "    plt.xlabel('PCA feature')\n",
    "    plt.ylabel('Explained Variance')\n",
    "    plt.xticks(features)\n",
    "\n",
    "    if export == True:\n",
    "    \n",
    "        # exporting the plot\n",
    "        plt.savefig('./analysis_images/top_customers_correlation_scree_plot.png')\n",
    "        \n",
    "    # displaying the plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA - BIG 5 TRAITS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scale Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# explanatory variables should be scaled before a PCA analysis algorithm \n",
    "\n",
    "# INSTANTIATING a StandardScaler() object\n",
    "scaler = StandardScaler()\n",
    "\n",
    "\n",
    "# FITTING the scaler with the data\n",
    "scaler.fit(big5)\n",
    "\n",
    "\n",
    "# TRANSFORMING our data after fit\n",
    "X_scaled = scaler.transform(big5)\n",
    "\n",
    "\n",
    "# converting scaled data into a DataFrame\n",
    "big5_scaled = pd.DataFrame(X_scaled)\n",
    "\n",
    "\n",
    "# reattaching column names\n",
    "big5_scaled.columns = big5.columns\n",
    "\n",
    "\n",
    "# checking pre- and post-scaling variance\n",
    "print(pd.np.var(big5), '\\n\\n')\n",
    "print(pd.np.var(big5_scaled))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transform PCA Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# INSTANTIATING a PCA object with no limit to principal components\n",
    "pca = PCA(n_components = None,\n",
    "            random_state = 802)\n",
    "\n",
    "\n",
    "# FITTING and TRANSFORMING the scaled data\n",
    "big5_pca = pca.fit_transform(big5_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# EVALUATE PCA ALGORITHM \n",
    "\n",
    "# component number counter\n",
    "component_number = 0\n",
    "\n",
    "# looping over each principal component (.explained_variance_ratio_)\n",
    "for variance in pca.explained_variance_ratio_:\n",
    "    component_number += 1\n",
    "    \n",
    "    print(f\"PC {component_number} : {variance.round(3)}\")\n",
    "    \n",
    "\n",
    "# checking to make sure PCA algorithm is good to proceed \n",
    "print(f\"\"\"Sum  : {(pca.explained_variance_ratio_).sum().round()}\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Insights:** The sum of all explained variance ratios is 1.0, which means model is good to proceed. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Principal Components Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1) MAX MODEL:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# VISUALIZING the pca \n",
    "scree_plot(pca_object = pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "####################\n",
    "### Max Model\n",
    "####################\n",
    "\n",
    "# transposing pca components\n",
    "factor_loadings_df = pd.DataFrame(pd.np.transpose(pca.components_))\n",
    "\n",
    "# naming rows as original features\n",
    "factor_loadings_df = factor_loadings_df.set_index(big5_scaled.columns)\n",
    "\n",
    "# displaying max model\n",
    "print(factor_loadings_df)\n",
    "\n",
    "# saving to Excel to easily reduce number of principal components\n",
    "# factor_loadings_df.to_excel('big5_customer_factor_loadings.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2) LIMITED MODEL:** \n",
    "\n",
    "Reduce model to contain reasonable number of principal components; following the 'elbow cut-off rule' or '80-20 rule'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# INSTANTIATING a new model using the first three principal components\n",
    "pca_4 = PCA(n_components =4,\n",
    "            random_state = 219)\n",
    "\n",
    "\n",
    "# FITTING and TRANSFORMING the purchases_scaled\n",
    "big_pca_4 = pca_4.fit_transform(big5_scaled)\n",
    "\n",
    "\n",
    "# calling the scree_plot function\n",
    "scree_plot(pca_object = pca_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "##################\n",
    "### Limited Model\n",
    "##################\n",
    "\n",
    "# transposing pca components \n",
    "factor_loadings_4 = pd.DataFrame(pd.np.transpose(pca_4.components_))\n",
    "\n",
    "# naming rows as original features\n",
    "factor_loadings_4 = factor_loadings_4.set_index(big5_scaled.columns)\n",
    "\n",
    "\n",
    "# displaying max model\n",
    "print(factor_loadings_4.round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA - BIG 5 PERSONA "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Persona Development "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taking into considerations of any correlation above 0.50 and both positive and negative outputs of the reduced PCA model, persona was developed as follow: \n",
    "\n",
    "\n",
    "\n",
    "**PC 1: AMEANABLE**    \n",
    "- People who are curious about the world and others around them. \n",
    "- They are mindful of details,  eager to learn and easy to be persuaded if it means they are exploring and enjoying new horizons in a scheduled manner. \n",
    "\n",
    "\n",
    "\n",
    "**PC 2: EQUANIMOUS**\n",
    "- People who are calm and has evenness of temper.\n",
    "- They are composed when in the face of stimuli, events and/or situations that tends to provoke certain reactions in others. \n",
    "\n",
    "\n",
    "\n",
    "**PC 3: OBSESSIVE**\n",
    "- People who strives for the best in an emotional manner, therefore, experiences a tremendous amount of stress.\n",
    "- Given the amount of things they worry about, they tend to be more reserved, gets upset easily and anxious when things fall out of place. \n",
    "\n",
    "\n",
    "\n",
    "**PC 4: INDECISIVE**\n",
    "- People who see endless possibilities but has trouble making decisions.\n",
    "- They tend to become 'unintentional' procrastinators because they have put off making decisions for so long that they run out of time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# naming each principal component\n",
    "factor_loadings_4.columns = ['AMEANABLE',\n",
    "                             'EQUANIMOUS',\n",
    "                             'OBSESSIVE',\n",
    "                             'INDECISIVE'] \n",
    "\n",
    "# checking the result\n",
    "factor_loadings_4.round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analyze Factor Loadings for Customers "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**STRATEGY TO IDENTIFY POTENTIAL CUSTOMER GROUPS:**\n",
    "\n",
    "1) Looking at any PC component, there are some groups with very high or very low factor loadings \n",
    "\n",
    "2) Find the percentage of customers who exhibit/ do not exhibit a specific trait, and only noting findings that can be of value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "deletable": false,
    "editable": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# PREPARE TO IDENTIFY GROUPS\n",
    "\n",
    "# analyzing factor strengths per customer\n",
    "big5_pca_reduced = pca_4.transform(big5_scaled)\n",
    "\n",
    "# converting to a DataFrame\n",
    "big5_pca_df = pd.DataFrame(big5_pca_reduced)\n",
    "\n",
    "# renaming columns\n",
    "big5_pca_df.columns = factor_loadings_4.columns\n",
    "\n",
    "# checking the results\n",
    "big5_pca_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# TRAIT: EQUANIMOUS\n",
    "\n",
    "# percentage of customers who DO exhibiting this psychology \n",
    "do = len(big5_pca_df['EQUANIMOUS'][big5_pca_df['EQUANIMOUS'] > 1.0]) / \\\n",
    "    len(big5_pca_df)\n",
    "\n",
    "# percentage of customers who DO NOT exhibiting this psychology \n",
    "do_not = len(big5_pca_df['EQUANIMOUS'][big5_pca_df['EQUANIMOUS'] <- 1.0]) / \\\n",
    "        len(big5_pca_df)\n",
    "\n",
    "print(f\"\"\"\n",
    "Percentage of Customers: \n",
    "-----------------\n",
    "Do exhibit this behavior:     {do}\n",
    "Do not exhibit this behavior: {do_not}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Insights:**\n",
    "- 20% of customers has a high level of equanimity\n",
    "- 18% of customers exhibit the opposite psychology  \n",
    "- Since the percentage of customers who do exhibit equanimity is higher, we should consider this potential customer groups "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA - HULT DNA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scale Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# explanatory variables should be scaled before developing a PCA analysis algorithm \n",
    "\n",
    "# INSTANTIATING a StandardScaler() object\n",
    "scaler = StandardScaler()\n",
    "\n",
    "\n",
    "# FITTING the scaler with the data\n",
    "scaler.fit(hult)\n",
    "\n",
    "\n",
    "# TRANSFORMING our data after fit\n",
    "X_scaled = scaler.transform(hult)\n",
    "\n",
    "\n",
    "# converting scaled data into a DataFrame\n",
    "hult_scaled = pd.DataFrame(X_scaled)\n",
    "\n",
    "\n",
    "# reattaching column names\n",
    "hult_scaled.columns = hult.columns\n",
    "\n",
    "\n",
    "# checking pre- and post-scaling variance\n",
    "print(pd.np.var(hult), '\\n\\n')\n",
    "print(pd.np.var(hult_scaled))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transform PCA Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# INSTANTIATING a PCA object with no limit to principal components\n",
    "pca = PCA(n_components = None,\n",
    "            random_state = 802)\n",
    "\n",
    "\n",
    "# FITTING and TRANSFORMING the scaled data\n",
    "hult_pca = pca.fit_transform(hult_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# EVALUATE PCA ALGORITHM \n",
    "\n",
    "# component number counter\n",
    "component_number = 0\n",
    "\n",
    "# looping over each principal component (.explained_variance_ratio_)\n",
    "for variance in pca.explained_variance_ratio_:\n",
    "    component_number += 1\n",
    "    \n",
    "    print(f\"PC {component_number} : {variance.round(3)}\")\n",
    "    \n",
    "\n",
    "# checking to make sure PCA algorithm is good to proceed \n",
    "print(f\"\"\"Sum  : {(pca.explained_variance_ratio_).sum().round()}\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Insights:** The sum of all explained variance ratios is 1.0, which means model is good to proceed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Principal Component Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1) MAX MODEL:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# VISUALIZING the pca \n",
    "scree_plot(pca_object = pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "####################\n",
    "### Max Model\n",
    "####################\n",
    "\n",
    "# transposing pca components\n",
    "factor_loadings_df = pd.DataFrame(pd.np.transpose(pca.components_))\n",
    "\n",
    "# naming rows as original features\n",
    "factor_loadings_df = factor_loadings_df.set_index(hult_scaled.columns)\n",
    "\n",
    "\n",
    "# displaying max model\n",
    "print(factor_loadings_df)\n",
    "\n",
    "# saving to Excel to easily reduce number of principal components\n",
    "# factor_loadings_df.to_excel('hult_customer_factor_loadings.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2) LIMITED MODEL:**\n",
    "\n",
    "Reduce model to contain reasonable number of principal components; following the 'elbow cut-off rule' or '80-20 rule'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# INSTANTIATING a new model using the first three principal components\n",
    "pca_2 = PCA(n_components =2,\n",
    "            random_state = 219)\n",
    "\n",
    "\n",
    "# FITTING and TRANSFORMING the purchases_scaled\n",
    "big_pca_2 = pca_2.fit_transform(hult_scaled)\n",
    "\n",
    "\n",
    "# calling the scree_plot function\n",
    "scree_plot(pca_object = pca_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "##################\n",
    "### Limited Model\n",
    "##################\n",
    "\n",
    "# transposing pca components \n",
    "factor_loadings_2 = pd.DataFrame(pd.np.transpose(pca_2.components_))\n",
    "\n",
    "# naming rows as original features\n",
    "factor_loadings_2 = factor_loadings_2.set_index(hult_scaled.columns)\n",
    "\n",
    "\n",
    "# displaying max model\n",
    "print(factor_loadings_2.round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA - HULT DNA PERSONA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Persona Development"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Taking into considerations of any correlation above 0.50 and both positive and negative outputs of the reduced PCA model, persona was developed as follow:\n",
    "\n",
    "**PC 1: APATHETIC** \n",
    "- People who exhibits a lack of interest in interactions with others, feel unmotivated and uninterested in daily tasks. \n",
    "- Apathy is not a negative thing, but rather, it's the \"conservation of energy\" (\"Apathy Is Misunderstood\", 2016).\n",
    "- People who are apathetic can ignore the noise and focus on things that matter most to them. \n",
    "\n",
    "\n",
    "**PC 2: CEREBRAL**\n",
    "- People who are deep thinkers; making decisions based on intelligence instead of emotions.\n",
    "- In the world of new ideas, they tend to be ahead.\n",
    "- Their weak point is shooting for the best and unable to bend and persuade others to follow them. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# naming each principal component\n",
    "factor_loadings_2.columns = ['APATHETIC',\n",
    "                             'CEREBRAL'] \n",
    "\n",
    "# checking the result\n",
    "factor_loadings_2.round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analyze Factor Loadings for Customers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**STRATEGY TO IDENTIFY POTENTIAL CUSTOMER GROUPS:**\n",
    "\n",
    "1) Looking at any PC component, there are some groups with very high or very low factor loadings\n",
    "\n",
    "2) Find the percentage of customers who exhibit/ do not exhibit a specific trait, and only noting findings that can be of value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# PREPARE TO IDENTIFY GROUPS\n",
    "\n",
    "# analyzing factor strengths per customer\n",
    "hult_pca_reduced = pca_2.transform(hult_scaled)\n",
    "\n",
    "# converting to a DataFrame\n",
    "hult_pca_df = pd.DataFrame(hult_pca_reduced)\n",
    "\n",
    "# renaming columns\n",
    "hult_pca_df.columns = factor_loadings_2.columns\n",
    "\n",
    "# checking the results\n",
    "hult_pca_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# BEHAVIOR: CEREBRAL\n",
    "\n",
    "# percentage of customers who DO exhibiting this behavior \n",
    "do = len(hult_pca_df['CEREBRAL'][hult_pca_df['CEREBRAL'] > 1.0]) / \\\n",
    "    len(hult_pca_df)\n",
    "\n",
    "# percentage of customers who DO NOT exhibiting this behavior \n",
    "do_not = len(hult_pca_df['CEREBRAL'][hult_pca_df['CEREBRAL'] <- 1.0]) / \\\n",
    "        len(hult_pca_df)\n",
    "\n",
    "print(f\"\"\"\n",
    "Percentage of Customers: \n",
    "-----------------\n",
    "Do exhibit this behavior:     {do}\n",
    "Do not exhibit this behavior: {do_not}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Insights:**\n",
    "- Very small percentage of customers exhibit/do not exhibit this behavior\n",
    "- For that reason, we will not focus on this potential customer group"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CLUSTERING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CUSTOMER GROUPING - BIG 5 TRAIT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# scaling before clustering \n",
    "\n",
    "# INSTANTIATING a StandardScaler() object\n",
    "scaler = StandardScaler()\n",
    "\n",
    "\n",
    "# FITTING the scaler with the data\n",
    "scaler.fit(big5_pca_df)\n",
    "\n",
    "\n",
    "# TRANSFORMING our data after fit\n",
    "X_scaled_pca = scaler.transform(big5_pca_df)\n",
    "\n",
    "\n",
    "# converting scaled data into a DataFrame\n",
    "pca_scaled = pd.DataFrame(X_scaled_pca)\n",
    "\n",
    "\n",
    "# reattaching column names\n",
    "pca_scaled.columns = ['AMEANABLE','EQUANIMOUS', 'OBSESSIVE', 'INDECISIVE'] \n",
    "\n",
    "\n",
    "# checking pre- and post-scaling variance\n",
    "print(pd.np.var(big5_pca_df), '\\n\\n')\n",
    "print(pd.np.var(pca_scaled))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Begin Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Steps taken was as follow:\n",
    "    \n",
    "1) Develop a dendogram to visualize the potential number of clusters \n",
    "\n",
    "2) Plot to determine the number of clusters \n",
    "\n",
    "3) Store cluster centers into a data frame \n",
    "\n",
    "4) Name clusters for easy analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# STEP 1: Develop a dendogram to visualize the potential number of clusters\n",
    "\n",
    "# grouping data based on Ward distance\n",
    "# standard_mergings_ward = linkage(y = pca_scaled,  \n",
    "                                 # method = 'ward',\n",
    "                                 # optimal_ordering = True)\n",
    "\n",
    "\n",
    "# setting plot size\n",
    "# fig, ax = plt.subplots(figsize=(8, 8))\n",
    "\n",
    "# developing a dendrogram\n",
    "# dendrogram(Z = standard_mergings_ward,\n",
    "           # leaf_rotation = 90,\n",
    "           # leaf_font_size = 6)\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# STEP 2: Plot to determine the number of clusters\n",
    "\n",
    "# calling the inertia_plot() function\n",
    "# interia_plot(data = pca_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "####################################\n",
    "# CLUSTER: 4\n",
    "####################################\n",
    "\n",
    "# INSTANTIATING a k-Means object with five clusters\n",
    "customers_k_pca = KMeans(n_clusters   = 4,\n",
    "                        random_state = 219)\n",
    "\n",
    "\n",
    "# fitting the object to the data\n",
    "customers_k_pca.fit(pca_scaled)\n",
    "\n",
    "\n",
    "# converting the clusters to a DataFrame\n",
    "customers_kmeans_pca = pd.DataFrame({'Cluster': customers_k_pca.labels_})\n",
    "\n",
    "\n",
    "# checking the results\n",
    "print(customers_kmeans_pca.iloc[: , 0].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# STEP 3: Store cluster centers into a data frame\n",
    "\n",
    "# storing cluster centers\n",
    "centroids_pca = customers_k_pca.cluster_centers_\n",
    "\n",
    "\n",
    "# converting cluster centers into a DataFrame\n",
    "centroids_pca_df = pd.DataFrame(centroids_pca)\n",
    "\n",
    "\n",
    "# renaming principal components\n",
    "centroids_pca_df.columns = ['AMENABLE','EQUANIMOUS', 'OBSESSIVE', 'INDECISIVE'] \n",
    "\n",
    "\n",
    "# checking results (clusters = rows, pc = columns)\n",
    "centroids_pca_df.round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**STEP 4: Naming clusters for easy analysis**\n",
    "\n",
    "\n",
    "- Cluster 0: **INDIFFERENT** - calm and has no ideology; most likely go with the flow  \n",
    "- Cluster 1: **PASSIONATE**  - open to discover new things and has tendency to be obsessive about it \n",
    "- Cluster 2: **SPONTANEOUS** - quick to make decisions and has no strings attached \n",
    "- Cluster 3: **TEMPERAMENTAL** - constant switch in mood that then hinders the decision-making process "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FINAL OUTPUT  - BIG 5 TRAITS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aggregate Results: Demographic Features + Big 5 + Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# concatenating cluster memberships with principal components\n",
    "clst_pca_df = pd.concat([customers_kmeans_pca,\n",
    "                         big5_pca_df],\n",
    "                         axis = 1)\n",
    "\n",
    "\n",
    "# checking results\n",
    "clst_pca_df\n",
    "\n",
    "# concatenating demographic information with pca-clusters\n",
    "final_pca_clust_df = pd.concat([computer.loc[ : , ['What laptop do you currently have?', \n",
    "                                                   'What laptop would you buy in next assuming if all laptops cost the same?']],\n",
    "                                clst_pca_df],\n",
    "                                axis = 1)\n",
    "\n",
    "\n",
    "# renaming columns\n",
    "final_pca_clust_df.columns = ['Current Laptop',\n",
    "                              'Future Laptop',\n",
    "                              'Cluster',\n",
    "                              'Ameanable',\n",
    "                              'Equanimous',\n",
    "                              'Obsessive',\n",
    "                              'Indecisive']\n",
    "\n",
    "# renaming clusters \n",
    "cluster_names = {0 : 'Indifferent',\n",
    "                 1 : 'Passionate',\n",
    "                 2 : 'Spontaneous',\n",
    "                 3 : 'Temperamental'}\n",
    "\n",
    "final_pca_clust_df['Cluster'].replace(cluster_names, inplace = True)\n",
    "\n",
    "\n",
    "# adding a productivity step\n",
    "big5_df = final_pca_clust_df\n",
    "\n",
    "# checking results\n",
    "big5_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analyze Final Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "deletable": false,
    "editable": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# CURRENT LAPTOPS + BIG 5\n",
    "####################################\n",
    "\n",
    "# setting figure size\n",
    "fig, ax = plt.subplots(figsize = (15, 10))\n",
    "\n",
    "\n",
    "# Ameanable\n",
    "plt.subplot(2, 2, 1)\n",
    "sns.boxplot(x = 'Current Laptop',\n",
    "            y = 'Ameanable',\n",
    "            hue = 'Cluster',\n",
    "            data = big5_df)\n",
    "\n",
    "\n",
    "# Equanimous \n",
    "plt.subplot(2, 2, 2)\n",
    "sns.boxplot(x    = 'Current Laptop',\n",
    "            y    = 'Equanimous',\n",
    "            hue  = 'Cluster',\n",
    "            data = big5_df)\n",
    "\n",
    "\n",
    "# Obsessive \n",
    "plt.subplot(2, 2, 3)\n",
    "sns.boxplot(x    = 'Current Laptop',\n",
    "            y    = 'Obsessive',\n",
    "            hue  = 'Cluster',\n",
    "            data = big5_df)\n",
    "\n",
    "\n",
    "# Indecsive \n",
    "plt.subplot(2, 2, 4)\n",
    "sns.boxplot(x    = 'Current Laptop',\n",
    "            y    = 'Indecisive',\n",
    "            hue  = 'Cluster',\n",
    "            data = big5_df)\n",
    "\n",
    "\n",
    "# formatting and displaying all plots\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Insights**:\n",
    "- Areas that can derive insights: \n",
    "    - Amenable (Indifferent and Spontaneous groups towards Macbook) \n",
    "    - Equanimous (Temperamental group towards Macbook) \n",
    "    - Obsessive (Indifferent and Spontaneous towards Macbook) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# FUTURE LAPTOPS + BIG 5\n",
    "####################################\n",
    "\n",
    "# setting figure size\n",
    "fig, ax = plt.subplots(figsize = (15, 10))\n",
    "\n",
    "\n",
    "# Ameanable\n",
    "plt.subplot(2, 2, 1)\n",
    "sns.boxplot(x = 'Future Laptop',\n",
    "            y = 'Ameanable',\n",
    "            hue = 'Cluster',\n",
    "            data = big5_df)\n",
    "\n",
    "\n",
    "# Equanimous \n",
    "plt.subplot(2, 2, 2)\n",
    "sns.boxplot(x    = 'Future Laptop',\n",
    "            y    = 'Equanimous',\n",
    "            hue  = 'Cluster',\n",
    "            data = big5_df)\n",
    "\n",
    "\n",
    "# Obsessive \n",
    "plt.subplot(2, 2, 3)\n",
    "sns.boxplot(x    = 'Future Laptop',\n",
    "            y    = 'Obsessive',\n",
    "            hue  = 'Cluster',\n",
    "            data = big5_df)\n",
    "\n",
    "\n",
    "# Indecsive \n",
    "plt.subplot(2, 2, 4)\n",
    "sns.boxplot(x    = 'Future Laptop',\n",
    "            y    = 'Indecisive',\n",
    "            hue  = 'Cluster',\n",
    "            data = big5_df)\n",
    "\n",
    "\n",
    "# formatting and displaying all plots\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Insights**:\n",
    "- Areas that can derive insights: \n",
    "    -  Equanimous + Obsessive (Passionate & Spontaneous groups and Windows laptop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CUSTOMER GROUPING - HULT DNA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# scaling before clustering \n",
    "\n",
    "# INSTANTIATING a StandardScaler() object\n",
    "scaler = StandardScaler()\n",
    "\n",
    "\n",
    "# FITTING the scaler with the data\n",
    "scaler.fit(hult_pca_df)\n",
    "\n",
    "\n",
    "# TRANSFORMING our data after fit\n",
    "X_scaled_pca = scaler.transform(hult_pca_df)\n",
    "\n",
    "\n",
    "# converting scaled data into a DataFrame\n",
    "pca_scaled = pd.DataFrame(X_scaled_pca)\n",
    "\n",
    "\n",
    "# reattaching column names\n",
    "pca_scaled.columns = ['APATHETIC','CEREBRAL'] \n",
    "\n",
    "\n",
    "# checking pre- and post-scaling variance\n",
    "print(pd.np.var(hult_pca_df), '\\n\\n')\n",
    "print(pd.np.var(pca_scaled))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Begin Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Steps taken was as follow:\n",
    "\n",
    "1) Develop a dendogram to visualize the potential number of clusters\n",
    "\n",
    "2) Plot to determine the number of clusters\n",
    "\n",
    "3) Store cluster centers into a data frame\n",
    "\n",
    "4) Name clusters for easy analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# STEP 1: Develop a dendogram to visualize the potential number of clusters\n",
    "\n",
    "# grouping data based on Ward distance\n",
    "# standard_mergings_ward = linkage(y = pca_scaled,  \n",
    "                                 # method = 'ward',\n",
    "                                 # optimal_ordering = True)\n",
    "\n",
    "\n",
    "# setting plot size\n",
    "# fig, ax = plt.subplots(figsize=(8, 8))\n",
    "\n",
    "# developing a dendrogram\n",
    "# dendrogram(Z = standard_mergings_ward,\n",
    "           # leaf_rotation = 90,\n",
    "           # leaf_font_size = 6)\n",
    "\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# STEP 2: Plot to determine the number of clusters\n",
    "\n",
    "# calling the inertia_plot() function\n",
    "# interia_plot(data = pca_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "####################################\n",
    "# CLUSTER: 3\n",
    "####################################\n",
    "\n",
    "# INSTANTIATING a k-Means object with five clusters\n",
    "customers_k_pca = KMeans(n_clusters   = 3,\n",
    "                        random_state = 219)\n",
    "\n",
    "\n",
    "# fitting the object to the data\n",
    "customers_k_pca.fit(pca_scaled)\n",
    "\n",
    "\n",
    "# converting the clusters to a DataFrame\n",
    "customers_kmeans_pca = pd.DataFrame({'Cluster': customers_k_pca.labels_})\n",
    "\n",
    "\n",
    "# checking the results\n",
    "print(customers_kmeans_pca.iloc[: , 0].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# STEP 4: Store cluster centers into a data frame\n",
    "\n",
    "# storing cluster centers\n",
    "centroids_pca = customers_k_pca.cluster_centers_\n",
    "\n",
    "\n",
    "# converting cluster centers into a DataFrame\n",
    "centroids_pca_df = pd.DataFrame(centroids_pca)\n",
    "\n",
    "\n",
    "# renaming principal components\n",
    "centroids_pca_df.columns = ['APATHETIC','CEREBRAL'] \n",
    "\n",
    "\n",
    "# checking results (clusters = rows, pc = columns)\n",
    "centroids_pca_df.round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**STEP 4: Naming clusters for easy analysis**\n",
    "\n",
    "- Cluster 0: **TREND-FOLLOWER** - has little curiosity nor thinks too much and will follow the status-quo \n",
    "- Cluster 1: **REALIST** - exhibit curiosity and deeply thinks about all aspects; weighing all pros and cons \n",
    "- Cluster 2: **AUTOGENICIST** - the 'Independent Thinker'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FINAL OUTPUT - HULT DNA "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aggregate Results: Demographic Features + Hult DNA + Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# concatenating cluster memberships with principal components\n",
    "clst_pca_df = pd.concat([customers_kmeans_pca,\n",
    "                         hult_pca_df],\n",
    "                         axis = 1)\n",
    "\n",
    "\n",
    "# checking results\n",
    "clst_pca_df\n",
    "\n",
    "# concatenating demographic information with pca-clusters\n",
    "final_pca_clust_df = pd.concat([computer.loc[ : , ['What laptop do you currently have?',\n",
    "                                                   'What laptop would you buy in next assuming if all laptops cost the same?']],\n",
    "                                clst_pca_df],\n",
    "                                axis = 1)\n",
    "\n",
    "\n",
    "# renaming columns\n",
    "final_pca_clust_df.columns = ['Current Laptop',\n",
    "                              'Future Laptop',\n",
    "                              'Cluster',\n",
    "                              'Apathetic',\n",
    "                              'Cerebral']\n",
    "\n",
    "# renaming clusters \n",
    "cluster_names = {0 : 'Trend-Follower',\n",
    "                 1 : 'Realist',\n",
    "                 2 : 'Autogenicist'}\n",
    "\n",
    "final_pca_clust_df['Cluster'].replace(cluster_names, inplace = True)\n",
    "\n",
    "\n",
    "# adding a productivity step\n",
    "hultdna_df = final_pca_clust_df\n",
    "\n",
    "# checking results\n",
    "hultdna_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analyze Final Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# CURRENT LAPTOPS + HULT DNA \n",
    "####################################\n",
    "\n",
    "# setting figure size\n",
    "fig, ax = plt.subplots(figsize = (15, 10))\n",
    "\n",
    "\n",
    "# Apathetic\n",
    "plt.subplot(2, 2, 1)\n",
    "sns.boxplot(x = 'Current Laptop',\n",
    "            y = 'Apathetic',\n",
    "            hue = 'Cluster',\n",
    "            data = hultdna_df)\n",
    "\n",
    "\n",
    "# Cerebral \n",
    "plt.subplot(2, 2, 2)\n",
    "sns.boxplot(x    = 'Current Laptop',\n",
    "            y    = 'Cerebral',\n",
    "            hue  = 'Cluster',\n",
    "            data = hultdna_df)\n",
    "\n",
    "\n",
    "# formatting and displaying all plots\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Insights**:\n",
    "- No big difference between Macbook vs Windows laptop in both 'Apathetic' and 'Cerebral' boxplots \n",
    "- Leave very litte room for insight, therefore, will focus on other areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# FUTURE LAPTOPS + HULT DNA \n",
    "####################################\n",
    "\n",
    "# setting figure size\n",
    "fig, ax = plt.subplots(figsize = (15, 10))\n",
    "\n",
    "\n",
    "# Apathetic\n",
    "plt.subplot(2, 2, 1)\n",
    "sns.boxplot(x = 'Future Laptop',\n",
    "            y = 'Apathetic',\n",
    "            hue = 'Cluster',\n",
    "            data = hultdna_df)\n",
    "\n",
    "\n",
    "# Cerebral \n",
    "plt.subplot(2, 2, 2)\n",
    "sns.boxplot(x    = 'Future Laptop',\n",
    "            y    = 'Cerebral',\n",
    "            hue  = 'Cluster',\n",
    "            data = hultdna_df)\n",
    "\n",
    "\n",
    "# formatting and displaying all plots\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Insights**:\n",
    "- Areas that can derive insights: \n",
    "    - Apathetic (Realist and Trend-Follower groups and Macbook) - perhaps, consider 'Chromebook' as a benchmark\n",
    "    - Cerebral (Trend-Follower group towards Windows laptop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# APPENDICES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**APPENDIX A**: Outline of Big Five Personality Traits and Hult DNA Criteria \n",
    "\n",
    "**What are the Big Five Personality traits?**\n",
    "- Openness - open to new ideas and experiences.\n",
    "- Conscientiousness - goal-directed, persistent, and organized.\n",
    "- Extraversion - motivated by surroundings.\n",
    "- Agreeableness - puts others' interests and needs ahead of their own\n",
    "- Neuroticism - sensitive to stress and negative emotional triggers\n",
    "\n",
    "**What are Hult DNA traits?**\n",
    "- Thinking\n",
    "    - Show self-awareness\n",
    "    - Embraces changes\n",
    "    - Demonstrate dynamic thinking\n",
    "- Communicating\n",
    "    - Speaks and listen skillfully\n",
    "    - Influence confidently\n",
    "    - Present idea effectively\n",
    "- Team Building\n",
    "    - Foster collaborative relationships\n",
    "    - Inspire productivity\n",
    "    - Resolve conflict constructively\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# REFERENCES "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Apathy Is Misunderstood\".(2016). Medium. Retrieved February 1, 2021, from https://circa-navigate.corsairs.network/apathy-is-misunderstood-f3855a5ae33a\n",
    "\n",
    "Bialik, K. (2020, March 2). “How Millennials Compare with Prior Generations.” Pew Research Center's Social & Demographic Trends Project. Retrieved February 1, 2021, from  www.pewsocialtrends.org/essay/millennial-life-how-young-adulthood-today-compares-with-prior-generations/\n",
    "\n",
    "Bona, C. (2021, January 8). “How Marketers Can Win with Gen Z and Millennials Post-COVID-19.” BCG Global, BCG Global. Retrieved February 1, 2021, from www.bcg.com/publications/2020/how-marketers-can-win-with-gen-z-millennials-post-covid\n",
    "\n",
    "Caldwell, M. (2020, December 26). “Is It Better to Take Financial Risks or Be Financially Conservative?”. The Balance. Retrieved February 1, 2021, from www.thebalance.com/should-i-be-financially-conservative-2385839\n",
    "\n",
    "Francis, T., & Hoefel, F. (2020, December 16). 'True Gen': Generation Z and its implications for companies. Retrieved January 31, 2021, from https://www.mckinsey.com/industries/consumer-packaged-goods/our-insights/true-gen-generation-z-and-its-implications-for-companies\n",
    "\n",
    "Fingas, J. (2021, January 31). “Chromebook Demand More than Doubled in 2020 Due to the Pandemic.” Engadget. Retrieved February 1, 2021, from www.engadget.com/chromebook-shipments-double-due-to-pandemic-193424657.html\n",
    "\n",
    "Howard, C. (n.d.). Men are from PCs, women are from Macs. Retrieved January 31, 2021, from http://www.applematters.com/article/men_are_from_pcs_women_are_from_macs/index.html\n",
    "\n",
    "Kelly, O. (2020), Common Obsessive Behaviors Among People With OCD, RetrievedFebruary 1, 2021, from https://www.verywellmind.com/what-are-common-obsessive-behaviors-2510679\n",
    "\n",
    "\"Mac vs PC People: Personality Traits & Aesthetic/Media Choices\". (2009, November 24). Retrieved January 31, 2021, from https://kellynford.com/2009/11/24/mac-vs-pc-people-personality-traits-aestheticmedia-choices/\n",
    "\n",
    "Nottrodt, J. (2020, April 20). \"The Cheapest Places in the World to Buy Apple Devices\". Retrieved January 31, 2021, from https://toomanyadapters.com/cheapest-places-world-buy-apple-devices/\n",
    "\n",
    "Rahul, M.(2019, May 23). “[Survey] Most Students Prefer Macs over PCs.” MSPoweruser. Retrieved February 1, 2021, from mspoweruser.com/survey-most-students-prefer-macs-over-pcs/\n",
    "\n",
    "Shaheem, S. (2019). \"Why every leader needs a growth mindset. Hult International Business School\". Retrieved February 1, 2021, from https://www.hult.edu/blog/why-every-leader-needs-growth-mindset/\n",
    "\n",
    "Stangel, L. (2018). \"A little less in Japan, way more in Brazil — here’s how much Apple's revamped Macbook will cost around the world\". Retrieved February 1, 2021 from https://www.bizjournals.com/sanjose/news/2016/10/28/a-little-less-in-japan-way-more-in-brazil-here-s.html\n",
    "\n",
    "\"The Big Five Personality Test (BFPT)\". (n.d.). Retrieved February 1, 2021, from https://sites.temple.edu/rtassessment/files/2018/10/Table_BFPT.pdf\n",
    "\n",
    "\"What Are the Big 5 Personality Traits?\". (n.d.). Verywell Mind. Retrieved February 1, 2021, from https://www.verywellmind.com/the-big-five-personality-dimensions-2795422\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
